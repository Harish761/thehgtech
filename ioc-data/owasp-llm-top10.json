{
  "version": "2.0",
  "year": 2025,
  "vulnerabilities": [
    {
      "rank": 1,
      "id": "LLM01",
      "name": "Prompt Injection",
      "description": "A Prompt Injection Vulnerability occurs when user prompts alter the LLM\u2019s behavior or output in unintended ways. These inputs can affect the model even if they are imperceptible to humans, therefore prompt injections do not need to be human-visible/readable, as long as the content is parsed by the m...",
      "severity": "critical",
      "preventionStrategies": 18,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM01_PromptInjection.md"
    },
    {
      "rank": 2,
      "id": "LLM02",
      "name": "Sensitive Information Disclosure",
      "description": "Sensitive information can affect both the LLM and its application context. This includes personal identifiable information (PII), financial details, health records, confidential business data, security credentials, and legal documents. Proprietary models may also have unique training methods and sou...",
      "severity": "critical",
      "preventionStrategies": 26,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM02_SensitiveInformationDisclosure.md"
    },
    {
      "rank": 3,
      "id": "LLM03",
      "name": "Supply Chain Vulnerabilities",
      "description": "LLM supply chains are susceptible to various vulnerabilities, which can affect the integrity of training data, models, and deployment platforms. These risks can result in biased outputs, security breaches, or system failures. While traditional software vulnerabilities focus on issues like code flaws...",
      "severity": "critical",
      "preventionStrategies": 22,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM03_SupplyChain.md"
    },
    {
      "rank": 4,
      "id": "LLM04",
      "name": "Data and Model Poisoning",
      "description": "Data poisoning occurs when pre-training, fine-tuning, or embedding data is manipulated to introduce vulnerabilities, backdoors, or biases. This manipulation can compromise model security, performance, or ethical behavior, leading to harmful outputs or impaired capabilities. Common risks include degr...",
      "severity": "high",
      "preventionStrategies": 5,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM04_DataModelPoisoning.md"
    },
    {
      "rank": 5,
      "id": "LLM05",
      "name": "Improper Output Handling",
      "description": "Improper Output Handling refers specifically to insufficient validation, sanitization, and handling of the outputs generated by large language models before they are passed downstream to other components and systems. Since LLM-generated content can be controlled by prompt input, this behavior is sim...",
      "severity": "high",
      "preventionStrategies": 6,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM05_ImproperOutputHandling.md"
    },
    {
      "rank": 6,
      "id": "LLM06",
      "name": "Excessive Agency",
      "description": "An LLM-based system is often granted a degree of agency by its developer - the ability to call functions or interface with other systems via extensions (sometimes referred to as tools, skills or plugins by different vendors) to undertake actions in response to a prompt. The decision over which exten...",
      "severity": "high",
      "preventionStrategies": 14,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM06_ExcessiveAgency.md"
    },
    {
      "rank": 7,
      "id": "LLM07",
      "name": "System Prompt Leakage",
      "description": "The system prompt leakage vulnerability in LLMs refers to the risk that the system prompts or instructions used to steer the behavior of the model can also contain sensitive information that was not intended to be discovered. System prompts are designed to guide the model's output based on the requi...",
      "severity": "medium",
      "preventionStrategies": 10,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM07_SystemPromptLeakage.md"
    },
    {
      "rank": 8,
      "id": "LLM08",
      "name": "Vector and Embedding Weaknesses",
      "description": "Vectors and embeddings vulnerabilities present significant security risks in systems utilizing Retrieval Augmented Generation (RAG) with Large Language Models (LLMs). Weaknesses in how vectors and embeddings are generated, stored, or retrieved can be exploited by malicious actions (intentional or un...",
      "severity": "medium",
      "preventionStrategies": 15,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM08_VectorAndEmbeddingWeaknesses.md"
    },
    {
      "rank": 9,
      "id": "LLM09",
      "name": "Misinformation",
      "description": "Misinformation from LLMs poses a core vulnerability for applications relying on these models. Misinformation occurs when LLMs produce false or misleading information that appears credible. This vulnerability can lead to security breaches, reputational damage, and legal liability.\n\nOne of the major c...",
      "severity": "medium",
      "preventionStrategies": 14,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM09_Misinformation.md"
    },
    {
      "rank": 10,
      "id": "LLM10",
      "name": "Unbounded Consumption",
      "description": "Unbounded Consumption refers to the process where a Large Language Model (LLM) generates outputs based on input queries or prompts. Inference is a critical function of LLMs, involving the application of learned patterns and knowledge to produce relevant responses or predictions.\n\nAttacks designed to...",
      "severity": "medium",
      "preventionStrategies": 28,
      "sourceUrl": "https://github.com/OWASP/www-project-top-10-for-large-language-model-applications/blob/main/2_0_vulns/LLM10_UnboundedConsumption.md"
    }
  ],
  "stats": {
    "total": 10,
    "critical": 3,
    "high": 3
  },
  "lastUpdated": "2025-12-16T02:05:23.438194+05:30"
}